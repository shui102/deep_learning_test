{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# prepare dataset\n",
    "# x,y是矩阵，3行1列 也就是说总共有3个数据，每个数据只有1个特征\n",
    "x_data = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "y_data = torch.tensor([[2.0], [4.0], [6.0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#design model using class\n",
    "\"\"\"\n",
    "our model class should be inherit from nn.Module, which is base class for all neural network modules.\n",
    "member methods __init__() and forward() have to be implemented\n",
    "class nn.linear contain two member Tensors: weight and bias\n",
    "class nn.Linear has implemented the magic method __call__(),which enable the instance of the class can\n",
    "be called just like a function.Normally the forward() will be called \n",
    "\"\"\"\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # (1,1)是指输入x和输出y的特征维度，这里数据集中的x和y的特征都是1维的\n",
    "        # 该线性层需要学习的参数是w和b  获取w/b的方式分别是~linear.weight/linear.bias\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    " \n",
    "model = LinearModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# construct loss and optimizer\n",
    "# criterion = torch.nn.MSELoss(size_average = False)\n",
    "criterion = torch.nn.MSELoss(reduction = 'sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01) # model.parameters()自动完成参数的初始化操作，这个地方我可能理解错了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.03171858564019203\n",
      "1 0.031262677162885666\n",
      "2 0.030813345685601234\n",
      "3 0.030370529741048813\n",
      "4 0.02993405982851982\n",
      "5 0.029503900557756424\n",
      "6 0.029079880565404892\n",
      "7 0.02866196259856224\n",
      "8 0.028250019997358322\n",
      "9 0.027843903750181198\n",
      "10 0.02744385600090027\n",
      "11 0.027049466967582703\n",
      "12 0.026660684496164322\n",
      "13 0.026277566328644753\n",
      "14 0.02589993178844452\n",
      "15 0.02552764117717743\n",
      "16 0.02516077645123005\n",
      "17 0.024799203500151634\n",
      "18 0.024442782625555992\n",
      "19 0.024091478437185287\n",
      "20 0.023745307698845863\n",
      "21 0.02340405061841011\n",
      "22 0.023067615926265717\n",
      "23 0.022736147046089172\n",
      "24 0.022409290075302124\n",
      "25 0.022087251767516136\n",
      "26 0.021769924089312553\n",
      "27 0.021456975489854813\n",
      "28 0.021148644387722015\n",
      "29 0.020844675600528717\n",
      "30 0.02054516039788723\n",
      "31 0.02024983800947666\n",
      "32 0.01995887979865074\n",
      "33 0.019672010093927383\n",
      "34 0.01938924752175808\n",
      "35 0.019110605120658875\n",
      "36 0.018835969269275665\n",
      "37 0.018565308302640915\n",
      "38 0.018298516049981117\n",
      "39 0.018035506829619408\n",
      "40 0.01777631603181362\n",
      "41 0.017520785331726074\n",
      "42 0.017268963158130646\n",
      "43 0.017020858824253082\n",
      "44 0.016776185482740402\n",
      "45 0.016535067930817604\n",
      "46 0.016297457739710808\n",
      "47 0.016063297167420387\n",
      "48 0.015832390636205673\n",
      "49 0.015604861080646515\n",
      "50 0.015380587428808212\n",
      "51 0.015159533359110355\n",
      "52 0.014941678382456303\n",
      "53 0.014726981520652771\n",
      "54 0.014515308663249016\n",
      "55 0.014306670054793358\n",
      "56 0.014101137407124043\n",
      "57 0.013898441568017006\n",
      "58 0.01369872409850359\n",
      "59 0.013501823879778385\n",
      "60 0.013307743705809116\n",
      "61 0.013116507790982723\n",
      "62 0.012927950359880924\n",
      "63 0.012742262333631516\n",
      "64 0.012559058144688606\n",
      "65 0.012378614395856857\n",
      "66 0.012200691737234592\n",
      "67 0.012025384232401848\n",
      "68 0.011852521449327469\n",
      "69 0.01168217882514\n",
      "70 0.01151429396122694\n",
      "71 0.011348824948072433\n",
      "72 0.011185684241354465\n",
      "73 0.011024927720427513\n",
      "74 0.010866506025195122\n",
      "75 0.010710306465625763\n",
      "76 0.010556402616202831\n",
      "77 0.010404733940958977\n",
      "78 0.010255152359604836\n",
      "79 0.010107751935720444\n",
      "80 0.009962562471628189\n",
      "81 0.009819351136684418\n",
      "82 0.009678245522081852\n",
      "83 0.009539155289530754\n",
      "84 0.0094020189717412\n",
      "85 0.009266944602131844\n",
      "86 0.009133742190897465\n",
      "87 0.009002452716231346\n",
      "88 0.008873099461197853\n",
      "89 0.008745579980313778\n",
      "90 0.008619869127869606\n",
      "91 0.008496037684381008\n",
      "92 0.00837387889623642\n",
      "93 0.008253529667854309\n",
      "94 0.008134984411299229\n",
      "95 0.00801799539476633\n",
      "96 0.007902808487415314\n",
      "97 0.00778920017182827\n",
      "98 0.007677295245230198\n",
      "99 0.0075669437646865845\n",
      "100 0.007458179257810116\n",
      "101 0.007351030129939318\n",
      "102 0.007245388347655535\n",
      "103 0.0071412427350878716\n",
      "104 0.0070386226288974285\n",
      "105 0.006937461905181408\n",
      "106 0.006837768480181694\n",
      "107 0.006739499047398567\n",
      "108 0.006642608437687159\n",
      "109 0.006547195836901665\n",
      "110 0.006453071255236864\n",
      "111 0.00636032409965992\n",
      "112 0.006268933415412903\n",
      "113 0.006178807932883501\n",
      "114 0.006090033799409866\n",
      "115 0.006002496927976608\n",
      "116 0.005916260182857513\n",
      "117 0.005831246264278889\n",
      "118 0.0057473983615636826\n",
      "119 0.0056647928431630135\n",
      "120 0.005583388730883598\n",
      "121 0.005503165069967508\n",
      "122 0.005424057133495808\n",
      "123 0.005346099846065044\n",
      "124 0.005269315093755722\n",
      "125 0.005193546414375305\n",
      "126 0.005118946079164743\n",
      "127 0.005045319441705942\n",
      "128 0.0049728695303201675\n",
      "129 0.004901391454041004\n",
      "130 0.004830952733755112\n",
      "131 0.0047615086659789085\n",
      "132 0.004693101160228252\n",
      "133 0.0046256547793745995\n",
      "134 0.00455913320183754\n",
      "135 0.004493626765906811\n",
      "136 0.00442903209477663\n",
      "137 0.004365408327430487\n",
      "138 0.004302652552723885\n",
      "139 0.00424079829826951\n",
      "140 0.004179876763373613\n",
      "141 0.004119784105569124\n",
      "142 0.004060597158968449\n",
      "143 0.004002246540039778\n",
      "144 0.003944701515138149\n",
      "145 0.003888008650392294\n",
      "146 0.0038321292959153652\n",
      "147 0.003777050878852606\n",
      "148 0.0037228036671876907\n",
      "149 0.003669287310913205\n",
      "150 0.003616546280682087\n",
      "151 0.0035645589232444763\n",
      "152 0.003513351082801819\n",
      "153 0.0034628487192094326\n",
      "154 0.003413096070289612\n",
      "155 0.003364027012139559\n",
      "156 0.003315688343718648\n",
      "157 0.0032680549193173647\n",
      "158 0.003221073653548956\n",
      "159 0.0031747855246067047\n",
      "160 0.003129171207547188\n",
      "161 0.003084199968725443\n",
      "162 0.0030398620292544365\n",
      "163 0.0029961541295051575\n",
      "164 0.0029531256295740604\n",
      "165 0.0029106815345585346\n",
      "166 0.00286884349770844\n",
      "167 0.0028276173397898674\n",
      "168 0.00278696627356112\n",
      "169 0.002746917074546218\n",
      "170 0.0027074632234871387\n",
      "171 0.0026685381308197975\n",
      "172 0.002630184404551983\n",
      "173 0.0025923950597643852\n",
      "174 0.0025551174767315388\n",
      "175 0.002518421970307827\n",
      "176 0.0024822265841066837\n",
      "177 0.002446528756991029\n",
      "178 0.0024113808758556843\n",
      "179 0.0023767086677253246\n",
      "180 0.002342560328543186\n",
      "181 0.002308907685801387\n",
      "182 0.0022757065016776323\n",
      "183 0.0022430159151554108\n",
      "184 0.0022107583936303854\n",
      "185 0.0021790058817714453\n",
      "186 0.0021477043628692627\n",
      "187 0.002116842893883586\n",
      "188 0.002086388412863016\n",
      "189 0.0020564154256135225\n",
      "190 0.0020268659573048353\n",
      "191 0.001997746294364333\n",
      "192 0.0019690280314534903\n",
      "193 0.00194073049351573\n",
      "194 0.0019128485582768917\n",
      "195 0.0018853303045034409\n",
      "196 0.0018582443008199334\n",
      "197 0.001831540954299271\n",
      "198 0.0018052285304293036\n",
      "199 0.0017792780417948961\n",
      "200 0.001753712771460414\n",
      "201 0.0017284922068938613\n",
      "202 0.001703667570836842\n",
      "203 0.0016791705274954438\n",
      "204 0.0016550470609217882\n",
      "205 0.0016312694642692804\n",
      "206 0.0016078016487881541\n",
      "207 0.0015846958849579096\n",
      "208 0.001561931916512549\n",
      "209 0.0015394811052829027\n",
      "210 0.0015173694118857384\n",
      "211 0.0014955638907849789\n",
      "212 0.0014740501064807177\n",
      "213 0.001452871598303318\n",
      "214 0.0014319936744868755\n",
      "215 0.0014114155201241374\n",
      "216 0.0013911359710618854\n",
      "217 0.0013711473438888788\n",
      "218 0.001351425307802856\n",
      "219 0.001332009444013238\n",
      "220 0.0013128584250807762\n",
      "221 0.001294007059186697\n",
      "222 0.0012753938790410757\n",
      "223 0.0012570720864459872\n",
      "224 0.00123900780454278\n",
      "225 0.0012211899738758802\n",
      "226 0.0012036606203764677\n",
      "227 0.0011863680556416512\n",
      "228 0.0011693101841956377\n",
      "229 0.0011525118025019765\n",
      "230 0.0011359428754076362\n",
      "231 0.0011196183040738106\n",
      "232 0.0011035066563636065\n",
      "233 0.0010876593878492713\n",
      "234 0.0010720257414504886\n",
      "235 0.00105661666020751\n",
      "236 0.0010414468124508858\n",
      "237 0.0010264668380841613\n",
      "238 0.0010117117781192064\n",
      "239 0.0009971719700843096\n",
      "240 0.000982841243967414\n",
      "241 0.0009687119163572788\n",
      "242 0.0009548089583404362\n",
      "243 0.0009410670027136803\n",
      "244 0.0009275469346903265\n",
      "245 0.000914228439796716\n",
      "246 0.0009010899811983109\n",
      "247 0.0008881333051249385\n",
      "248 0.000875383906532079\n",
      "249 0.0008628052892163396\n",
      "250 0.0008503957651555538\n",
      "251 0.0008381602820008993\n",
      "252 0.0008261303300969303\n",
      "253 0.0008142439182847738\n",
      "254 0.0008025455754250288\n",
      "255 0.0007910186541266739\n",
      "256 0.0007796465652063489\n",
      "257 0.0007684422307647765\n",
      "258 0.0007573877228423953\n",
      "259 0.0007465198286809027\n",
      "260 0.0007357935537584126\n",
      "261 0.0007252090726979077\n",
      "262 0.0007147883297875524\n",
      "263 0.0007045109523460269\n",
      "264 0.000694384565576911\n",
      "265 0.0006844029412604868\n",
      "266 0.0006745706778019667\n",
      "267 0.0006648814305663109\n",
      "268 0.0006553233251906931\n",
      "269 0.0006458950228989124\n",
      "270 0.000636617187410593\n",
      "271 0.000627474975772202\n",
      "272 0.0006184609956108034\n",
      "273 0.0006095711141824722\n",
      "274 0.0006008039927110076\n",
      "275 0.0005921768024563789\n",
      "276 0.0005836625350639224\n",
      "277 0.0005752741708420217\n",
      "278 0.0005670101381838322\n",
      "279 0.0005588664207607508\n",
      "280 0.0005508334143087268\n",
      "281 0.0005429046577773988\n",
      "282 0.0005351086729206145\n",
      "283 0.0005274104769341648\n",
      "284 0.0005198436556383967\n",
      "285 0.0005123682785779238\n",
      "286 0.0005050019826740026\n",
      "287 0.0004977512871846557\n",
      "288 0.0004905968089587986\n",
      "289 0.00048353755846619606\n",
      "290 0.0004765967605635524\n",
      "291 0.00046974647557362914\n",
      "292 0.00046299080713652074\n",
      "293 0.0004563374677672982\n",
      "294 0.00044979146332480013\n",
      "295 0.00044331728713586926\n",
      "296 0.0004369374073576182\n",
      "297 0.0004306653281673789\n",
      "298 0.00042448288877494633\n",
      "299 0.000418382027419284\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(300):\n",
    "    y_pred = model(x_data) # forward:predict\n",
    "    loss = criterion(y_pred, y_data) # forward: loss\n",
    "    print(epoch, loss.item())\n",
    " \n",
    "    optimizer.zero_grad() # the grad computer by .backward() will be accumulated. so before backward, remember set the grad to zero\n",
    "    loss.backward() # backward: autograd，自动计算梯度\n",
    "    optimizer.step() # update 参数，即更新w和b的值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w =  1.9863831996917725\n",
      "b =  0.03095427341759205\n",
      "y_pred =  tensor([[7.9765]])\n"
     ]
    }
   ],
   "source": [
    "print('w = ', model.linear.weight.item())\n",
    "print('b = ', model.linear.bias.item())\n",
    " \n",
    "x_test = torch.tensor([[4.0]])\n",
    "y_test = model(x_test)\n",
    "print('y_pred = ', y_test.data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
